# OpenVINO GenAI WhisperPipeline â€” Intel GPU accelerated speech-to-text
# Lightweight Python server replacing whisper.cpp (SYCL/OpenVINO/CUDA)

FROM ubuntu:24.04

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv \
    intel-opencl-icd libze1 \
    libsndfile1 ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Install CPU-only PyTorch first (required by audio-separator + other deps)
RUN pip3 install --break-system-packages --no-cache-dir \
    torch torchaudio --index-url https://download.pytorch.org/whl/cpu

# Install audio-separator with CPU ONNX runtime for vocal separation
RUN pip3 install --break-system-packages --no-cache-dir "audio-separator[cpu]" && \
    python3 -c "from audio_separator.separator import Separator; print('audio-separator OK')"

COPY requirements.txt /app/
RUN pip3 install --break-system-packages --no-cache-dir -r /app/requirements.txt

COPY server.py /app/
WORKDIR /app

ENV MODEL_ID=OpenVINO/distil-whisper-large-v3-int8-ov
ENV DEVICE=GPU
ENV PORT=8178
ENV ENABLE_VOCAL_SEP=1
ENV VOCAL_SEP_MODEL=UVR_MDXNET_KARA_2.onnx
# Prevent PyTorch from caching CUDA memory (we use CPU-only)
ENV PYTORCH_NO_CUDA_MEMORY_CACHING=1

EXPOSE 8178

CMD ["python3", "server.py"]
