# OpenVINO GenAI WhisperPipeline — Intel GPU accelerated speech-to-text
# Lightweight Python server replacing whisper.cpp (SYCL/OpenVINO/CUDA)
# Vocal separation uses MDX-Net ONNX (no PyTorch needed)

FROM ubuntu:24.04

RUN apt-get update && apt-get install -y --no-install-recommends \
    python3 python3-pip python3-venv \
    intel-opencl-icd libze1 \
    libsndfile1 ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# No PyTorch needed — vocal separation uses onnxruntime + numpy/scipy
COPY requirements.txt /app/
RUN pip3 install --break-system-packages --no-cache-dir -r /app/requirements.txt

COPY server.py vocal_separator.py /app/
WORKDIR /app

ENV MODEL_ID=OpenVINO/distil-whisper-large-v3-int8-ov
ENV DEVICE=GPU
ENV PORT=8178
ENV ENABLE_VOCAL_SEP=1
ENV VOCAL_SEP_MODEL=UVR_MDXNET_KARA_2.onnx

EXPOSE 8178

CMD ["python3", "server.py"]
