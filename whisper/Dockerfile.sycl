# whisper.cpp SYCL build for Intel Arc GPUs
# Uses whisper.cpp built-in HTTP server (whisper-server)

# Build stage
FROM intel/oneapi-basekit:2025.0.1-0-devel-ubuntu24.04 AS builder

RUN apt-get update && apt-get install -y --no-install-recommends \
    git cmake build-essential \
    && rm -rf /var/lib/apt/lists/*

# Clone and build whisper.cpp with SYCL support (pinned to stable release)
RUN git clone --depth 1 --branch v1.8.3 https://github.com/ggerganov/whisper.cpp.git /whisper
WORKDIR /whisper
RUN cmake -B build \
    -DGGML_SYCL=ON \
    -DGGML_SYCL_TARGET=INTEL \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_C_COMPILER=icx \
    -DCMAKE_CXX_COMPILER=icpx \
    -DBUILD_SHARED_LIBS=OFF
RUN cmake --build build --config Release -j$(nproc) --target whisper-server

# Runtime stage â€” needs oneAPI runtime for SYCL + Intel GPU drivers
FROM intel/oneapi-runtime:2025.0.1-0-devel-ubuntu24.04

# Install Intel GPU compute runtime (Level Zero + OpenCL) for Arc/iGPU
RUN apt-get update && apt-get install -y --no-install-recommends \
    intel-opencl-icd \
    level-zero \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /whisper/build/bin/whisper-server /usr/local/bin/
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh

# Create model directory
RUN mkdir -p /models

ENV WHISPER_MODEL=ggml-large-v3.bin

EXPOSE 8178

# Entrypoint queries FTML backend for the active model, then falls back to env var
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
