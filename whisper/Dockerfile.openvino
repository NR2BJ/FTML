# whisper.cpp OpenVINO build for Intel GPUs
# Alternative to SYCL backend â€” uses OpenVINO for inference acceleration

# Build stage
FROM intel/oneapi-basekit:2025.0.1-0-devel-ubuntu24.04 AS builder

RUN apt-get update && apt-get install -y --no-install-recommends \
    git cmake build-essential wget gnupg2 ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# Install OpenVINO
RUN wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB -O- | gpg --dearmor > /usr/share/keyrings/intel-openvino-archive-keyring.gpg \
    && echo "deb [signed-by=/usr/share/keyrings/intel-openvino-archive-keyring.gpg] https://apt.repos.intel.com/openvino/2024 ubuntu24 main" > /etc/apt/sources.list.d/openvino.list \
    && apt-get update && apt-get install -y --no-install-recommends openvino \
    && rm -rf /var/lib/apt/lists/*

# Clone and build whisper.cpp with OpenVINO support (pinned to stable release)
RUN git clone --depth 1 --branch v1.8.3 https://github.com/ggerganov/whisper.cpp.git /whisper
WORKDIR /whisper
RUN cmake -B build \
    -DGGML_OPENVINO=ON \
    -DCMAKE_BUILD_TYPE=Release \
    -DBUILD_SHARED_LIBS=OFF
RUN cmake --build build --config Release -j$(nproc) --target whisper-server

# Runtime stage
FROM intel/oneapi-runtime:2025.0.1-0-devel-ubuntu24.04

# Install OpenVINO runtime
RUN apt-get update && apt-get install -y --no-install-recommends \
    wget gnupg2 ca-certificates \
    && wget https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB -O- | gpg --dearmor > /usr/share/keyrings/intel-openvino-archive-keyring.gpg \
    && echo "deb [signed-by=/usr/share/keyrings/intel-openvino-archive-keyring.gpg] https://apt.repos.intel.com/openvino/2024 ubuntu24 main" > /etc/apt/sources.list.d/openvino.list \
    && apt-get update && apt-get install -y --no-install-recommends openvino \
    && rm -rf /var/lib/apt/lists/*

COPY --from=builder /whisper/build/bin/whisper-server /usr/local/bin/
COPY entrypoint.sh /usr/local/bin/entrypoint.sh
RUN chmod +x /usr/local/bin/entrypoint.sh

# Create model directory
RUN mkdir -p /models

ENV WHISPER_MODEL=ggml-large-v3-turbo.bin

EXPOSE 8178

# Entrypoint queries FTML backend for the active model, then falls back to env var
ENTRYPOINT ["/usr/local/bin/entrypoint.sh"]
