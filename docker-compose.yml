services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "${FTML_PORT:-7979}:80"
    depends_on:
      - backend
    networks:
      - homeserver-net
    restart: unless-stopped

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    expose:
      - "8080"
    volumes:
      - ${MEDIA_PATH:-/mnt/storage/video}:/media:ro
      - ftml_data:/data
    environment:
      - ADMIN_USERNAME=${ADMIN_USERNAME:-admin}
      - ADMIN_PASSWORD=${ADMIN_PASSWORD:-changeme}
      - JWT_SECRET=${JWT_SECRET:-change-this-secret}
      - MEDIA_PATH=/media
      - DATA_PATH=/data
      - DB_PATH=/data/videostream.db
      - SUBTITLE_PATH=/data/subtitles
      # WHISPER_MODEL_PATH no longer needed — models cached on whisper container
      - PORT=8080
      - LIBVA_DRIVER_NAME=iHD
    devices:
      - /dev/dri:/dev/dri
    group_add:
      - "${RENDER_GID:-109}"
    networks:
      - homeserver-net
    restart: unless-stopped

  # Whisper STT - OpenVINO GenAI (Intel Arc GPU accelerated)
  # Model is managed via web UI Settings — no MODEL_ID env var needed
  whisper:
    build:
      context: ./whisper
      dockerfile: Dockerfile.openvino-genai
    environment:
      - DEVICE=${WHISPER_DEVICE:-GPU}
    volumes:
      - whisper_models:/root/.cache/huggingface
      - ${MEDIA_PATH:-/mnt/storage/video}:/media:ro
    devices:
      - /dev/dri:/dev/dri
    group_add:
      - "${RENDER_GID:-109}"
    networks:
      - homeserver-net
    restart: unless-stopped

volumes:
  ftml_data:
    external: true
  whisper_models:
    external: true

networks:
  homeserver-net:
    external: true
